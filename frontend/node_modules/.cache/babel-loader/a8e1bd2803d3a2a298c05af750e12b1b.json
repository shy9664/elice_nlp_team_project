{"ast":null,"code":"var DEBUG = false; // `true` to print debugging info.\n\nvar TIMER = false; // `true` to time calls to `parse()` and print the results.\n\nvar debug = require('./debug')('parse');\n\nvar lex = require('./lexer');\n\nexports = module.exports = parse;\n\nvar _comments; // Whether comments are allowed.\n\n\nvar _depth; // Current block nesting depth.\n\n\nvar _position; // Whether to include line/column position.\n\n\nvar _tokens; // Array of lexical tokens.\n\n/**\r\n * Convert a CSS string or array of lexical tokens into a `stringify`-able AST.\r\n *\r\n * @param {String} css CSS string or array of lexical token\r\n * @param {Object} [options]\r\n * @param {Boolean} [options.comments=false] allow comment nodes in the AST\r\n * @returns {Object} `stringify`-able AST\r\n */\n\n\nfunction parse(css, options) {\n  var start; // Debug timer start.\n\n  options || (options = {});\n  _comments = !!options.comments;\n  _position = !!options.position;\n  _depth = 0; // Operate on a copy of the given tokens, or the lex()'d CSS string.\n\n  _tokens = Array.isArray(css) ? css.slice() : lex(css);\n  var rule;\n  var rules = [];\n  var token;\n  TIMER && (start = Date.now());\n\n  while (token = next()) {\n    rule = parseToken(token);\n    rule && rules.push(rule);\n  }\n\n  TIMER && debug('ran in', Date.now() - start + 'ms');\n  return {\n    type: \"stylesheet\",\n    stylesheet: {\n      rules: rules\n    }\n  };\n} // -- Functions --------------------------------------------------------------\n\n/**\r\n * Build an AST node from a lexical token.\r\n *\r\n * @param {Object} token lexical token\r\n * @param {Object} [override] object hash of properties that override those\r\n *   already in the token, or that will be added to the token.\r\n * @returns {Object} AST node\r\n */\n\n\nfunction astNode(token, override) {\n  override || (override = {});\n  var key;\n  var keys = ['type', 'name', 'value'];\n  var node = {}; // Avoiding [].forEach for performance reasons.\n\n  for (var i = 0; i < keys.length; ++i) {\n    key = keys[i];\n\n    if (token[key]) {\n      node[key] = override[key] || token[key];\n    }\n  }\n\n  keys = Object.keys(override);\n\n  for (i = 0; i < keys.length; ++i) {\n    key = keys[i];\n\n    if (!node[key]) {\n      node[key] = override[key];\n    }\n  }\n\n  if (_position) {\n    node.position = {\n      start: token.start,\n      end: token.end\n    };\n  }\n\n  DEBUG && debug('astNode:', JSON.stringify(node, null, 2));\n  return node;\n}\n/**\r\n * Remove a lexical token from the stack and return the removed token.\r\n *\r\n * @returns {Object} lexical token\r\n */\n\n\nfunction next() {\n  var token = _tokens.shift();\n\n  DEBUG && debug('next:', JSON.stringify(token, null, 2));\n  return token;\n} // -- Parse* Functions ---------------------------------------------------------\n\n/**\r\n * Convert an @-group lexical token to an AST node.\r\n *\r\n * @param {Object} token @-group lexical token\r\n * @returns {Object} @-group AST node\r\n */\n\n\nfunction parseAtGroup(token) {\n  _depth = _depth + 1; // As the @-group token is assembled, relevant token values are captured here\n  // temporarily. They will later be used as `tokenize()` overrides.\n\n  var overrides = {};\n\n  switch (token.type) {\n    case 'font-face':\n    case 'viewport':\n      overrides.declarations = parseDeclarations();\n      break;\n\n    case 'page':\n      overrides.prefix = token.prefix;\n      overrides.declarations = parseDeclarations();\n      break;\n\n    default:\n      overrides.prefix = token.prefix;\n      overrides.rules = parseRules();\n  }\n\n  return astNode(token, overrides);\n}\n/**\r\n * Convert an @import lexical token to an AST node.\r\n *\r\n * @param {Object} token @import lexical token\r\n * @returns {Object} @import AST node\r\n */\n\n\nfunction parseAtImport(token) {\n  return astNode(token);\n}\n/**\r\n * Convert an @charset token to an AST node.\r\n *\r\n * @param {Object} token @charset lexical token\r\n * @returns {Object} @charset node\r\n */\n\n\nfunction parseCharset(token) {\n  return astNode(token);\n}\n/**\r\n * Convert a comment token to an AST Node.\r\n *\r\n * @param {Object} token comment lexical token\r\n * @returns {Object} comment node\r\n */\n\n\nfunction parseComment(token) {\n  return astNode(token, {\n    text: token.text\n  });\n}\n\nfunction parseNamespace(token) {\n  return astNode(token);\n}\n/**\r\n * Convert a property lexical token to a property AST node.\r\n *\r\n * @returns {Object} property node\r\n */\n\n\nfunction parseProperty(token) {\n  return astNode(token);\n}\n/**\r\n * Convert a selector lexical token to a selector AST node.\r\n *\r\n * @param {Object} token selector lexical token\r\n * @returns {Object} selector node\r\n */\n\n\nfunction parseSelector(token) {\n  function trim(str) {\n    return str.trim();\n  }\n\n  return astNode(token, {\n    type: 'rule',\n    selectors: token.text.split(',').map(trim),\n    declarations: parseDeclarations(token)\n  });\n}\n/**\r\n * Convert a lexical token to an AST node.\r\n *\r\n * @returns {Object|undefined} AST node\r\n */\n\n\nfunction parseToken(token) {\n  switch (token.type) {\n    // Cases are listed in roughly descending order of probability.\n    case 'property':\n      return parseProperty(token);\n\n    case 'selector':\n      return parseSelector(token);\n\n    case 'at-group-end':\n      _depth = _depth - 1;\n      return;\n\n    case 'media':\n    case 'keyframes':\n      return parseAtGroup(token);\n\n    case 'comment':\n      if (_comments) {\n        return parseComment(token);\n      }\n\n      break;\n\n    case 'charset':\n      return parseCharset(token);\n\n    case 'import':\n      return parseAtImport(token);\n\n    case 'namespace':\n      return parseNamespace(token);\n\n    case 'font-face':\n    case 'supports':\n    case 'viewport':\n    case 'document':\n    case 'page':\n      return parseAtGroup(token);\n  }\n\n  DEBUG && debug('parseToken: unexpected token:', JSON.stringify(token));\n} // -- Parse Helper Functions ---------------------------------------------------\n\n/**\r\n * Iteratively parses lexical tokens from the stack into AST nodes until a\r\n * conditional function returns `false`, at which point iteration terminates\r\n * and any AST nodes collected are returned.\r\n *\r\n * @param {Function} conditionFn\r\n *   @param {Object} token the lexical token being parsed\r\n *   @returns {Boolean} `true` if the token should be parsed, `false` otherwise\r\n * @return {Array} AST nodes\r\n */\n\n\nfunction parseTokensWhile(conditionFn) {\n  var node;\n  var nodes = [];\n  var token;\n\n  while ((token = next()) && conditionFn && conditionFn(token)) {\n    node = parseToken(token);\n    node && nodes.push(node);\n  } // Place an unused non-`end` lexical token back onto the stack.\n\n\n  if (token && token.type !== 'end') {\n    _tokens.unshift(token);\n  }\n\n  return nodes;\n}\n/**\r\n * Convert a series of tokens into a sequence of declaration AST nodes.\r\n *\r\n * @returns {Array} declaration nodes\r\n */\n\n\nfunction parseDeclarations() {\n  return parseTokensWhile(function (token) {\n    return token.type === 'property' || token.type === 'comment';\n  });\n}\n/**\r\n * Convert a series of tokens into a sequence of rule nodes.\r\n *\r\n * @returns {Array} rule nodes\r\n */\n\n\nfunction parseRules() {\n  return parseTokensWhile(function () {\n    return _depth;\n  });\n}","map":{"version":3,"sources":["C:/Users/ghdus/OneDrive/바탕 화면/team-project/nlp-project-team2/frontend/node_modules/mensch/lib/parser.js"],"names":["DEBUG","TIMER","debug","require","lex","exports","module","parse","_comments","_depth","_position","_tokens","css","options","start","comments","position","Array","isArray","slice","rule","rules","token","Date","now","next","parseToken","push","type","stylesheet","astNode","override","key","keys","node","i","length","Object","end","JSON","stringify","shift","parseAtGroup","overrides","declarations","parseDeclarations","prefix","parseRules","parseAtImport","parseCharset","parseComment","text","parseNamespace","parseProperty","parseSelector","trim","str","selectors","split","map","parseTokensWhile","conditionFn","nodes","unshift"],"mappings":"AAAA,IAAIA,KAAK,GAAG,KAAZ,C,CAAmB;;AACnB,IAAIC,KAAK,GAAG,KAAZ,C,CAAmB;;AAEnB,IAAIC,KAAK,GAAGC,OAAO,CAAC,SAAD,CAAP,CAAmB,OAAnB,CAAZ;;AACA,IAAIC,GAAG,GAAGD,OAAO,CAAC,SAAD,CAAjB;;AAEAE,OAAO,GAAGC,MAAM,CAACD,OAAP,GAAiBE,KAA3B;;AAEA,IAAIC,SAAJ,C,CAAiB;;;AACjB,IAAIC,MAAJ,C,CAAiB;;;AACjB,IAAIC,SAAJ,C,CAAiB;;;AACjB,IAAIC,OAAJ,C,CAAiB;;AAEjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASJ,KAAT,CAAeK,GAAf,EAAoBC,OAApB,EAA6B;AAC3B,MAAIC,KAAJ,CAD2B,CAChB;;AAEXD,EAAAA,OAAO,KAAKA,OAAO,GAAG,EAAf,CAAP;AACAL,EAAAA,SAAS,GAAG,CAAC,CAACK,OAAO,CAACE,QAAtB;AACAL,EAAAA,SAAS,GAAG,CAAC,CAACG,OAAO,CAACG,QAAtB;AAEAP,EAAAA,MAAM,GAAG,CAAT,CAP2B,CAS3B;;AACAE,EAAAA,OAAO,GAAGM,KAAK,CAACC,OAAN,CAAcN,GAAd,IAAqBA,GAAG,CAACO,KAAJ,EAArB,GAAmCf,GAAG,CAACQ,GAAD,CAAhD;AAEA,MAAIQ,IAAJ;AACA,MAAIC,KAAK,GAAG,EAAZ;AACA,MAAIC,KAAJ;AAEArB,EAAAA,KAAK,KAAKa,KAAK,GAAGS,IAAI,CAACC,GAAL,EAAb,CAAL;;AAEA,SAAQF,KAAK,GAAGG,IAAI,EAApB,EAAyB;AACvBL,IAAAA,IAAI,GAAGM,UAAU,CAACJ,KAAD,CAAjB;AACAF,IAAAA,IAAI,IAAIC,KAAK,CAACM,IAAN,CAAWP,IAAX,CAAR;AACD;;AAEDnB,EAAAA,KAAK,IAAIC,KAAK,CAAC,QAAD,EAAYqB,IAAI,CAACC,GAAL,KAAaV,KAAd,GAAuB,IAAlC,CAAd;AAEA,SAAO;AACLc,IAAAA,IAAI,EAAE,YADD;AAELC,IAAAA,UAAU,EAAE;AACVR,MAAAA,KAAK,EAAEA;AADG;AAFP,GAAP;AAMD,C,CAED;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASS,OAAT,CAAiBR,KAAjB,EAAwBS,QAAxB,EAAkC;AAChCA,EAAAA,QAAQ,KAAKA,QAAQ,GAAG,EAAhB,CAAR;AAEA,MAAIC,GAAJ;AACA,MAAIC,IAAI,GAAG,CAAC,MAAD,EAAS,MAAT,EAAiB,OAAjB,CAAX;AACA,MAAIC,IAAI,GAAG,EAAX,CALgC,CAOhC;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,IAAI,CAACG,MAAzB,EAAiC,EAAED,CAAnC,EAAsC;AACpCH,IAAAA,GAAG,GAAGC,IAAI,CAACE,CAAD,CAAV;;AAEA,QAAIb,KAAK,CAACU,GAAD,CAAT,EAAgB;AACdE,MAAAA,IAAI,CAACF,GAAD,CAAJ,GAAYD,QAAQ,CAACC,GAAD,CAAR,IAAiBV,KAAK,CAACU,GAAD,CAAlC;AACD;AACF;;AAEDC,EAAAA,IAAI,GAAGI,MAAM,CAACJ,IAAP,CAAYF,QAAZ,CAAP;;AAEA,OAAKI,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGF,IAAI,CAACG,MAArB,EAA6B,EAAED,CAA/B,EAAkC;AAChCH,IAAAA,GAAG,GAAGC,IAAI,CAACE,CAAD,CAAV;;AAEA,QAAI,CAACD,IAAI,CAACF,GAAD,CAAT,EAAgB;AACdE,MAAAA,IAAI,CAACF,GAAD,CAAJ,GAAYD,QAAQ,CAACC,GAAD,CAApB;AACD;AACF;;AAED,MAAItB,SAAJ,EAAe;AACbwB,IAAAA,IAAI,CAAClB,QAAL,GAAgB;AACdF,MAAAA,KAAK,EAAEQ,KAAK,CAACR,KADC;AAEdwB,MAAAA,GAAG,EAAEhB,KAAK,CAACgB;AAFG,KAAhB;AAID;;AAEDtC,EAAAA,KAAK,IAAIE,KAAK,CAAC,UAAD,EAAaqC,IAAI,CAACC,SAAL,CAAeN,IAAf,EAAqB,IAArB,EAA2B,CAA3B,CAAb,CAAd;AAEA,SAAOA,IAAP;AACD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAAST,IAAT,GAAgB;AACd,MAAIH,KAAK,GAAGX,OAAO,CAAC8B,KAAR,EAAZ;;AACAzC,EAAAA,KAAK,IAAIE,KAAK,CAAC,OAAD,EAAUqC,IAAI,CAACC,SAAL,CAAelB,KAAf,EAAsB,IAAtB,EAA4B,CAA5B,CAAV,CAAd;AACA,SAAOA,KAAP;AACD,C,CAED;;AAEA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASoB,YAAT,CAAsBpB,KAAtB,EAA6B;AAC3Bb,EAAAA,MAAM,GAAGA,MAAM,GAAG,CAAlB,CAD2B,CAG3B;AACA;;AACA,MAAIkC,SAAS,GAAG,EAAhB;;AAEA,UAAQrB,KAAK,CAACM,IAAd;AACA,SAAK,WAAL;AACA,SAAK,UAAL;AACEe,MAAAA,SAAS,CAACC,YAAV,GAAyBC,iBAAiB,EAA1C;AACA;;AAEF,SAAK,MAAL;AACEF,MAAAA,SAAS,CAACG,MAAV,GAAmBxB,KAAK,CAACwB,MAAzB;AACAH,MAAAA,SAAS,CAACC,YAAV,GAAyBC,iBAAiB,EAA1C;AACA;;AAEF;AACEF,MAAAA,SAAS,CAACG,MAAV,GAAmBxB,KAAK,CAACwB,MAAzB;AACAH,MAAAA,SAAS,CAACtB,KAAV,GAAkB0B,UAAU,EAA5B;AAbF;;AAgBA,SAAOjB,OAAO,CAACR,KAAD,EAAQqB,SAAR,CAAd;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASK,aAAT,CAAuB1B,KAAvB,EAA8B;AAC5B,SAAOQ,OAAO,CAACR,KAAD,CAAd;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;;AACA,SAAS2B,YAAT,CAAsB3B,KAAtB,EAA6B;AAC3B,SAAOQ,OAAO,CAACR,KAAD,CAAd;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;;AACA,SAAS4B,YAAT,CAAsB5B,KAAtB,EAA6B;AAC3B,SAAOQ,OAAO,CAACR,KAAD,EAAQ;AAAC6B,IAAAA,IAAI,EAAE7B,KAAK,CAAC6B;AAAb,GAAR,CAAd;AACD;;AAED,SAASC,cAAT,CAAwB9B,KAAxB,EAA+B;AAC7B,SAAOQ,OAAO,CAACR,KAAD,CAAd;AACD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAAS+B,aAAT,CAAuB/B,KAAvB,EAA8B;AAC5B,SAAOQ,OAAO,CAACR,KAAD,CAAd;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASgC,aAAT,CAAuBhC,KAAvB,EAA8B;AAC5B,WAASiC,IAAT,CAAcC,GAAd,EAAmB;AACjB,WAAOA,GAAG,CAACD,IAAJ,EAAP;AACD;;AAED,SAAOzB,OAAO,CAACR,KAAD,EAAQ;AACpBM,IAAAA,IAAI,EAAE,MADc;AAEpB6B,IAAAA,SAAS,EAAEnC,KAAK,CAAC6B,IAAN,CAAWO,KAAX,CAAiB,GAAjB,EAAsBC,GAAtB,CAA0BJ,IAA1B,CAFS;AAGpBX,IAAAA,YAAY,EAAEC,iBAAiB,CAACvB,KAAD;AAHX,GAAR,CAAd;AAKD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAASI,UAAT,CAAoBJ,KAApB,EAA2B;AACzB,UAAQA,KAAK,CAACM,IAAd;AACA;AACA,SAAK,UAAL;AAAiB,aAAOyB,aAAa,CAAC/B,KAAD,CAApB;;AAEjB,SAAK,UAAL;AAAiB,aAAOgC,aAAa,CAAChC,KAAD,CAApB;;AAEjB,SAAK,cAAL;AAAqBb,MAAAA,MAAM,GAAGA,MAAM,GAAG,CAAlB;AAAqB;;AAE1C,SAAK,OAAL;AACA,SAAK,WAAL;AAAkB,aAAOiC,YAAY,CAACpB,KAAD,CAAnB;;AAElB,SAAK,SAAL;AAAgB,UAAId,SAAJ,EAAe;AAAE,eAAO0C,YAAY,CAAC5B,KAAD,CAAnB;AAA6B;;AAAC;;AAE/D,SAAK,SAAL;AAAgB,aAAO2B,YAAY,CAAC3B,KAAD,CAAnB;;AAChB,SAAK,QAAL;AAAe,aAAO0B,aAAa,CAAC1B,KAAD,CAApB;;AAEf,SAAK,WAAL;AAAkB,aAAO8B,cAAc,CAAC9B,KAAD,CAArB;;AAElB,SAAK,WAAL;AACA,SAAK,UAAL;AACA,SAAK,UAAL;AACA,SAAK,UAAL;AACA,SAAK,MAAL;AAAkB,aAAOoB,YAAY,CAACpB,KAAD,CAAnB;AAtBlB;;AAyBAtB,EAAAA,KAAK,IAAIE,KAAK,CAAC,+BAAD,EAAkCqC,IAAI,CAACC,SAAL,CAAelB,KAAf,CAAlC,CAAd;AACD,C,CAED;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASsC,gBAAT,CAA0BC,WAA1B,EAAuC;AACrC,MAAI3B,IAAJ;AACA,MAAI4B,KAAK,GAAG,EAAZ;AACA,MAAIxC,KAAJ;;AAEA,SAAO,CAACA,KAAK,GAAGG,IAAI,EAAb,KAAqBoC,WAAW,IAAIA,WAAW,CAACvC,KAAD,CAAtD,EAAgE;AAC9DY,IAAAA,IAAI,GAAGR,UAAU,CAACJ,KAAD,CAAjB;AACAY,IAAAA,IAAI,IAAI4B,KAAK,CAACnC,IAAN,CAAWO,IAAX,CAAR;AACD,GARoC,CAUrC;;;AACA,MAAIZ,KAAK,IAAIA,KAAK,CAACM,IAAN,KAAe,KAA5B,EAAmC;AACjCjB,IAAAA,OAAO,CAACoD,OAAR,CAAgBzC,KAAhB;AACD;;AAED,SAAOwC,KAAP;AACD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAASjB,iBAAT,GAA6B;AAC3B,SAAOe,gBAAgB,CAAC,UAAUtC,KAAV,EAAiB;AACvC,WAAQA,KAAK,CAACM,IAAN,KAAe,UAAf,IAA6BN,KAAK,CAACM,IAAN,KAAe,SAApD;AACD,GAFsB,CAAvB;AAGD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAASmB,UAAT,GAAsB;AACpB,SAAOa,gBAAgB,CAAC,YAAY;AAAE,WAAOnD,MAAP;AAAgB,GAA/B,CAAvB;AACD","sourcesContent":["var DEBUG = false; // `true` to print debugging info.\r\nvar TIMER = false; // `true` to time calls to `parse()` and print the results.\r\n\r\nvar debug = require('./debug')('parse');\r\nvar lex = require('./lexer');\r\n\r\nexports = module.exports = parse;\r\n\r\nvar _comments;   // Whether comments are allowed.\r\nvar _depth;      // Current block nesting depth.\r\nvar _position;   // Whether to include line/column position.\r\nvar _tokens;     // Array of lexical tokens.\r\n\r\n/**\r\n * Convert a CSS string or array of lexical tokens into a `stringify`-able AST.\r\n *\r\n * @param {String} css CSS string or array of lexical token\r\n * @param {Object} [options]\r\n * @param {Boolean} [options.comments=false] allow comment nodes in the AST\r\n * @returns {Object} `stringify`-able AST\r\n */\r\nfunction parse(css, options) {\r\n  var start; // Debug timer start.\r\n\r\n  options || (options = {});\r\n  _comments = !!options.comments;\r\n  _position = !!options.position;\r\n\r\n  _depth = 0;\r\n\r\n  // Operate on a copy of the given tokens, or the lex()'d CSS string.\r\n  _tokens = Array.isArray(css) ? css.slice() : lex(css);\r\n\r\n  var rule;\r\n  var rules = [];\r\n  var token;\r\n\r\n  TIMER && (start = Date.now());\r\n\r\n  while ((token = next())) {\r\n    rule = parseToken(token);\r\n    rule && rules.push(rule);\r\n  }\r\n\r\n  TIMER && debug('ran in', (Date.now() - start) + 'ms');\r\n\r\n  return {\r\n    type: \"stylesheet\",\r\n    stylesheet: {\r\n      rules: rules\r\n    }\r\n  };\r\n}\r\n\r\n// -- Functions --------------------------------------------------------------\r\n\r\n/**\r\n * Build an AST node from a lexical token.\r\n *\r\n * @param {Object} token lexical token\r\n * @param {Object} [override] object hash of properties that override those\r\n *   already in the token, or that will be added to the token.\r\n * @returns {Object} AST node\r\n */\r\nfunction astNode(token, override) {\r\n  override || (override = {});\r\n\r\n  var key;\r\n  var keys = ['type', 'name', 'value'];\r\n  var node = {};\r\n\r\n  // Avoiding [].forEach for performance reasons.\r\n  for (var i = 0; i < keys.length; ++i) {\r\n    key = keys[i];\r\n\r\n    if (token[key]) {\r\n      node[key] = override[key] || token[key];\r\n    }\r\n  }\r\n\r\n  keys = Object.keys(override);\r\n\r\n  for (i = 0; i < keys.length; ++i) {\r\n    key = keys[i];\r\n\r\n    if (!node[key]) {\r\n      node[key] = override[key];\r\n    }\r\n  }\r\n\r\n  if (_position) {\r\n    node.position = {\r\n      start: token.start,\r\n      end: token.end\r\n    };\r\n  }\r\n\r\n  DEBUG && debug('astNode:', JSON.stringify(node, null, 2));\r\n\r\n  return node;\r\n}\r\n\r\n/**\r\n * Remove a lexical token from the stack and return the removed token.\r\n *\r\n * @returns {Object} lexical token\r\n */\r\nfunction next() {\r\n  var token = _tokens.shift();\r\n  DEBUG && debug('next:', JSON.stringify(token, null, 2));\r\n  return token;\r\n}\r\n\r\n// -- Parse* Functions ---------------------------------------------------------\r\n\r\n/**\r\n * Convert an @-group lexical token to an AST node.\r\n *\r\n * @param {Object} token @-group lexical token\r\n * @returns {Object} @-group AST node\r\n */\r\nfunction parseAtGroup(token) {\r\n  _depth = _depth + 1;\r\n\r\n  // As the @-group token is assembled, relevant token values are captured here\r\n  // temporarily. They will later be used as `tokenize()` overrides.\r\n  var overrides = {};\r\n\r\n  switch (token.type) {\r\n  case 'font-face':\r\n  case 'viewport' :\r\n    overrides.declarations = parseDeclarations();\r\n    break;\r\n\r\n  case 'page':\r\n    overrides.prefix = token.prefix;\r\n    overrides.declarations = parseDeclarations();\r\n    break;\r\n\r\n  default:\r\n    overrides.prefix = token.prefix;\r\n    overrides.rules = parseRules();\r\n  }\r\n\r\n  return astNode(token, overrides);\r\n}\r\n\r\n/**\r\n * Convert an @import lexical token to an AST node.\r\n *\r\n * @param {Object} token @import lexical token\r\n * @returns {Object} @import AST node\r\n */\r\nfunction parseAtImport(token) {\r\n  return astNode(token);\r\n}\r\n\r\n/**\r\n * Convert an @charset token to an AST node.\r\n *\r\n * @param {Object} token @charset lexical token\r\n * @returns {Object} @charset node\r\n */\r\nfunction parseCharset(token) {\r\n  return astNode(token);\r\n}\r\n\r\n/**\r\n * Convert a comment token to an AST Node.\r\n *\r\n * @param {Object} token comment lexical token\r\n * @returns {Object} comment node\r\n */\r\nfunction parseComment(token) {\r\n  return astNode(token, {text: token.text});\r\n}\r\n\r\nfunction parseNamespace(token) {\r\n  return astNode(token);\r\n}\r\n\r\n/**\r\n * Convert a property lexical token to a property AST node.\r\n *\r\n * @returns {Object} property node\r\n */\r\nfunction parseProperty(token) {\r\n  return astNode(token);\r\n}\r\n\r\n/**\r\n * Convert a selector lexical token to a selector AST node.\r\n *\r\n * @param {Object} token selector lexical token\r\n * @returns {Object} selector node\r\n */\r\nfunction parseSelector(token) {\r\n  function trim(str) {\r\n    return str.trim();\r\n  }\r\n\r\n  return astNode(token, {\r\n    type: 'rule',\r\n    selectors: token.text.split(',').map(trim),\r\n    declarations: parseDeclarations(token)\r\n  });\r\n}\r\n\r\n/**\r\n * Convert a lexical token to an AST node.\r\n *\r\n * @returns {Object|undefined} AST node\r\n */\r\nfunction parseToken(token) {\r\n  switch (token.type) {\r\n  // Cases are listed in roughly descending order of probability.\r\n  case 'property': return parseProperty(token);\r\n\r\n  case 'selector': return parseSelector(token);\r\n\r\n  case 'at-group-end': _depth = _depth - 1; return;\r\n\r\n  case 'media'     :\r\n  case 'keyframes' :return parseAtGroup(token);\r\n\r\n  case 'comment': if (_comments) { return parseComment(token); } break;\r\n\r\n  case 'charset': return parseCharset(token);\r\n  case 'import': return parseAtImport(token);\r\n\r\n  case 'namespace': return parseNamespace(token);\r\n\r\n  case 'font-face':\r\n  case 'supports' :\r\n  case 'viewport' :\r\n  case 'document' :\r\n  case 'page'     : return parseAtGroup(token);\r\n  }\r\n\r\n  DEBUG && debug('parseToken: unexpected token:', JSON.stringify(token));\r\n}\r\n\r\n// -- Parse Helper Functions ---------------------------------------------------\r\n\r\n/**\r\n * Iteratively parses lexical tokens from the stack into AST nodes until a\r\n * conditional function returns `false`, at which point iteration terminates\r\n * and any AST nodes collected are returned.\r\n *\r\n * @param {Function} conditionFn\r\n *   @param {Object} token the lexical token being parsed\r\n *   @returns {Boolean} `true` if the token should be parsed, `false` otherwise\r\n * @return {Array} AST nodes\r\n */\r\nfunction parseTokensWhile(conditionFn) {\r\n  var node;\r\n  var nodes = [];\r\n  var token;\r\n\r\n  while ((token = next()) && (conditionFn && conditionFn(token))) {\r\n    node = parseToken(token);\r\n    node && nodes.push(node);\r\n  }\r\n\r\n  // Place an unused non-`end` lexical token back onto the stack.\r\n  if (token && token.type !== 'end') {\r\n    _tokens.unshift(token);\r\n  }\r\n\r\n  return nodes;\r\n}\r\n\r\n/**\r\n * Convert a series of tokens into a sequence of declaration AST nodes.\r\n *\r\n * @returns {Array} declaration nodes\r\n */\r\nfunction parseDeclarations() {\r\n  return parseTokensWhile(function (token) {\r\n    return (token.type === 'property' || token.type === 'comment');\r\n  });\r\n}\r\n\r\n/**\r\n * Convert a series of tokens into a sequence of rule nodes.\r\n *\r\n * @returns {Array} rule nodes\r\n */\r\nfunction parseRules() {\r\n  return parseTokensWhile(function () { return _depth; });\r\n}\r\n"]},"metadata":{},"sourceType":"script"}